{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): Only clang++ is supported. With g++, we end up with strange g++/OSX bugs.\n",
      "WARNING:theano.configdefaults:Only clang++ is supported. With g++, we end up with strange g++/OSX bugs.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import theano\n",
    "import lasagne\n",
    "import numpy as np\n",
    "\n",
    "import theano.tensor as T\n",
    "\n",
    "from utils import custom_sgd, iterate_minibatches\n",
    "from kron_layer import KronLayer, SimpleKronLayer\n",
    "from uv_kron_layer import UVKronLayer\n",
    "from lowrank_layer import LowRankLayer, SimpleLowRankLayer\n",
    "from theano.compile.nanguardmode import NanGuardMode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_custom_mlp(input_var=None, widths=None, drop_input=.2,\n",
    "                     drop_hidden=.5, type=\"dense\", rank=2):\n",
    "    # By default, this creates the same network as `build_mlp`, but it can be\n",
    "    # customized with respect to the number and size of hidden layers. This\n",
    "    # mostly showcases how creating a network in Python code can be a lot more\n",
    "    # flexible than a configuration file. Note that to make the code easier,\n",
    "    # all the layers are just called `network` -- there is no need to give them\n",
    "    # different names if all we return is the last one we created anyway; we\n",
    "    # just used different names above for clarity.\n",
    "\n",
    "    widths = widths if widths is not None else [100, 100]\n",
    "    manifolds = {}\n",
    "\n",
    "    # Input layer and dropout (with shortcut `dropout` for `DropoutLayer`):\n",
    "    network = lasagne.layers.InputLayer(shape=(None, 1, 28, 28), input_var=input_var)\n",
    "    \n",
    "    if drop_input:\n",
    "        network = lasagne.layers.dropout(network, p=drop_input)\n",
    "    # Hidden layers and dropout:\n",
    "    nonlin = lasagne.nonlinearities.rectify\n",
    "\n",
    "    \"\"\"\n",
    "    # Convolutional layer with 32 kernels of size 5x5. Strided and padded\n",
    "    # convolutions are supported as well; see the docstring.\n",
    "    network = lasagne.layers.Conv2DLayer(\n",
    "            network, num_filters=32, filter_size=(5, 5),\n",
    "            stride=1, pad=2,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.GlorotUniform())\n",
    "    # Expert note: Lasagne provides alternative convolutional layers that\n",
    "    # override Theano's choice of which implementation to use; for details\n",
    "    # please see http://lasagne.readthedocs.org/en/latest/user/tutorial.html.\n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "\n",
    "    # Another convolution with 32 5x5 kernels, and another 2x2 pooling:\n",
    "    network = lasagne.layers.Conv2DLayer(\n",
    "            network, num_filters=32, filter_size=(5, 5),\n",
    "            stride=1, pad=2,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "    \"\"\"\n",
    "\n",
    "    if type == \"dense\":\n",
    "        network = lasagne.layers.DenseLayer(\n",
    "            network, widths[0], nonlinearity=nonlin)\n",
    "    else:\n",
    "        if type == \"lowrank\":\n",
    "            network = LowRankLayer(network,\n",
    "                                   widths[0],\n",
    "                                   rank=rank,\n",
    "                                   name=\"rieman_low_rank_0\")\n",
    "            manifolds[\"rieman_low_rank_0\"] = network.manifold\n",
    "        elif type == \"slowrank\":\n",
    "            network = SimpleLowRankLayer(network,\n",
    "                                   widths[0],\n",
    "                                   rank=rank,\n",
    "                                   name=\"simple_low_rank_0\")\n",
    "        else:\n",
    "            raise ValueError(\"type must be one of 2 variants: lowrank' or 'slowrank', but is '{}'\".format(type))\n",
    "    for width in widths[1:]:\n",
    "        network = lasagne.layers.DenseLayer(\n",
    "                network, width, nonlinearity=nonlin)\n",
    "        if drop_hidden:\n",
    "            network = lasagne.layers.dropout(network, p=drop_hidden)\n",
    "    # Output layer:\n",
    "    softmax = lasagne.nonlinearities.softmax\n",
    "    network = lasagne.layers.DenseLayer(network, 10, nonlinearity=softmax)\n",
    "    return network, manifolds\n",
    "\n",
    "\n",
    "def generate_train_acc(input_X=None, target_y=None, widths=None, type=\"dense\", lr=1e-2, rank=2):\n",
    "    input_X = T.tensor4(\"X\") if input_X is None else input_X\n",
    "    target_y = T.vector(\"target Y integer\", dtype='int32') if target_y is None else target_y\n",
    "    widths = [100] if widths is None else widths\n",
    "    dense_output, manifolds = build_custom_mlp(input_X, widths=widths, type=type, rank=rank)\n",
    "\n",
    "    y_predicted = lasagne.layers.get_output(dense_output)\n",
    "\n",
    "\n",
    "    all_weights = lasagne.layers.get_all_params(dense_output)\n",
    "\n",
    "\n",
    "    loss = lasagne.objectives.categorical_crossentropy(y_predicted,target_y).mean()\n",
    "    accuracy = lasagne.objectives.categorical_accuracy(y_predicted,target_y).mean()\n",
    "\n",
    "    updates_sgd = custom_sgd(loss, all_weights, learning_rate=lr, manifolds=manifolds)\n",
    "\n",
    "\n",
    "    train_fun = theano.function([input_X,target_y],[loss, accuracy],updates=updates_sgd)#, mode=NanGuardMode(nan_is_error=True, inf_is_error=True, big_is_error=True))\n",
    "    accuracy_fun = theano.function([input_X,target_y],accuracy)#, mode=NanGuardMode(nan_is_error=True, inf_is_error=True, big_is_error=True))\n",
    "    return train_fun, accuracy_fun\n",
    "\n",
    "\n",
    "def comparison(X_train,y_train,X_val,y_val,X_test,y_test, rank=10, kron_params=None):\n",
    "    import pickle\n",
    "    n_trials = 5\n",
    "    kron_params = np.ones(n_trials, dtype=int) * rank if kron_params is None else kron_params\n",
    "    param_modifier = np.log(rank)\n",
    "    lr = theano.shared(np.array(0.001 / param_modifier, dtype=theano.config.floatX))\n",
    "    num_epochs = 250\n",
    "\n",
    "    batch_size = 100\n",
    "\n",
    "    hidden_units = [256]\n",
    "\n",
    "    trains, accs = generate_train_acc(widths=hidden_units, type=\"dense\", lr=lr)\n",
    "    trains, accs = list(zip(*([(trains, accs)]\n",
    "                              + [generate_train_acc(widths=hidden_units, type=\"lowrank\", lr=lr, rank=kron_param) for kron_param in kron_params]\n",
    "                              + [generate_train_acc(widths=hidden_units, type=\"slowrank\", lr=lr,rank=kron_param) for kron_param in kron_params])))\n",
    "\n",
    "    names = [\"dense\"] + [\"rieman_lowrank({})\".format(i) for i in range(n_trials)]\\\n",
    "                      + [\"simple_lowrank({})\".format(i) for i in range(n_trials)]\n",
    "    results = {}\n",
    "\n",
    "    for train, acc, name in zip(trains, accs, names):\n",
    "        res = {}\n",
    "        res[\"train_fun\"] = train\n",
    "        res[\"accuracy_fun\"] = acc\n",
    "        res[\"train_err\"] = []\n",
    "        res[\"train_acc\"] = []\n",
    "        res[\"epoch_times\"] = []\n",
    "        res[\"val_acc\"] = []\n",
    "        results[name] = res\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # learn rate annealing\n",
    "        if ((epoch + 1) % 100==0):\n",
    "            lr.set_value(lr.get_value() * 0.95)\n",
    "            print('Learning rate is decayed. It now becomes {}'.format(lr.get_value()))\n",
    "        for (res_name, res) in results.items():\n",
    "            train_err = 0\n",
    "            train_acc = 0\n",
    "            train_batches = 0\n",
    "            start_time = time.time()\n",
    "            for batch in iterate_minibatches(X_train, y_train,batch_size):\n",
    "                inputs, targets = batch\n",
    "                train_err_batch, train_acc_batch= res[\"train_fun\"](inputs, targets)\n",
    "                train_err += train_err_batch\n",
    "                train_acc += train_acc_batch\n",
    "                train_batches += 1\n",
    "\n",
    "            # And a full pass over the validation data:\n",
    "            val_acc = 0\n",
    "            val_batches = 0\n",
    "            for batch in iterate_minibatches(X_val, y_val, batch_size):\n",
    "                inputs, targets = batch\n",
    "                val_acc += res[\"accuracy_fun\"](inputs, targets)\n",
    "                val_batches += 1\n",
    "\n",
    "            # Then we print the results for this epoch:\n",
    "            print(\"for {}\".format(res_name))\n",
    "            print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "                epoch + 1, num_epochs, time.time() - start_time))\n",
    "\n",
    "            print(\"  training loss (in-iteration):\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "            print(\"  train accuracy:\\t\\t{:.2f} %\".format(\n",
    "                train_acc / train_batches * 100))\n",
    "            print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "                val_acc / val_batches * 100))\n",
    "            res[\"train_err\"].append(train_err / train_batches)\n",
    "            res[\"train_acc\"].append(train_acc / train_batches * 100)\n",
    "            res[\"val_acc\"].append(val_acc / val_batches * 100)\n",
    "        temp = {key: [results[key]['train_fun'], results[key]['accuracy_fun']] for key in results}\n",
    "        for res in results.values():\n",
    "            res.pop('train_fun')\n",
    "            res.pop('accuracy_fun')\n",
    "        \n",
    "        with open(\"compare_simpliest_nn_lowrank_{}_{}.dict\".format(hidden_units[0], rank), 'wb') as pickle_file:\n",
    "            pickle.dump(results, pickle_file)\n",
    "        for key in results:\n",
    "            results[key]['train_fun'] = temp[key][0]\n",
    "            results[key]['accuracy_fun'] = temp[key][1]\n",
    "\n",
    "def determine(X_train,y_train,X_val,y_val,X_test,y_test, type=\"lowrank\", lrates=None):\n",
    "    lrates = np.logspace(-3, -1, 5) if lrates is None else lrates\n",
    "    rank = 10\n",
    "    import pickle\n",
    "    num_epochs = 25\n",
    "\n",
    "    batch_size = 100\n",
    "\n",
    "    hidden_units = [256]\n",
    "\n",
    "    trains, accs = list(zip(*([generate_train_acc(widths=hidden_units, type=type, rank=rank) for lr in lrates])))\n",
    "\n",
    "    names = [\"{}({})\".format(type, lr) for lr in lrates]\n",
    "    results = {}\n",
    "\n",
    "    for train, acc, name in zip(trains, accs, names):\n",
    "        res = {}\n",
    "        res[\"train_fun\"] = train\n",
    "        res[\"accuracy_fun\"] = acc\n",
    "        res[\"train_err\"] = []\n",
    "        res[\"train_acc\"] = []\n",
    "        res[\"epoch_times\"] = []\n",
    "        res[\"val_acc\"] = []\n",
    "        results[name] = res\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for (res_name, res) in results.items():\n",
    "            train_err = 0\n",
    "            train_acc = 0\n",
    "            train_batches = 0\n",
    "            start_time = time.time()\n",
    "            for batch in iterate_minibatches(X_train, y_train,batch_size):\n",
    "                inputs, targets = batch\n",
    "                train_err_batch, train_acc_batch= res[\"train_fun\"](inputs, targets)\n",
    "                train_err += train_err_batch\n",
    "                train_acc += train_acc_batch\n",
    "                train_batches += 1\n",
    "\n",
    "            # And a full pass over the validation data:\n",
    "            val_acc = 0\n",
    "            val_batches = 0\n",
    "            for batch in iterate_minibatches(X_val, y_val, batch_size):\n",
    "                inputs, targets = batch\n",
    "                val_acc += res[\"accuracy_fun\"](inputs, targets)\n",
    "                val_batches += 1\n",
    "\n",
    "            # Then we print the results for this epoch:\n",
    "            print(\"for {}\".format(res_name))\n",
    "            print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "                epoch + 1, num_epochs, time.time() - start_time))\n",
    "\n",
    "            print(\"  training loss (in-iteration):\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "            print(\"  train accuracy:\\t\\t{:.2f} %\".format(\n",
    "                train_acc / train_batches * 100))\n",
    "            print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "                val_acc / val_batches * 100))\n",
    "            res[\"train_err\"].append(train_err / train_batches)\n",
    "            res[\"train_acc\"].append(train_acc / train_batches * 100)\n",
    "            res[\"val_acc\"].append(val_acc / val_batches * 100)\n",
    "        temp = {key: [results[key]['train_fun'], results[key]['accuracy_fun']] for key in results}\n",
    "        for res in results.values():\n",
    "            res.pop('train_fun')\n",
    "            res.pop('accuracy_fun')\n",
    "        \n",
    "        with open(\"determine_history_simpliest_nn{}.dict\".format(type), 'wb') as pickle_file:\n",
    "            pickle.dump(results, pickle_file)\n",
    "        for key in results:\n",
    "            results[key]['train_fun'] = temp[key][0]\n",
    "            results[key]['accuracy_fun'] = temp[key][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1, 28, 28) (50000,)\n",
      "for rieman_lowrank(0)\n",
      "Epoch 1 of 250 took 3.419s\n",
      "  training loss (in-iteration):\t\t2.252163\n",
      "  train accuracy:\t\t23.36 %\n",
      "  validation accuracy:\t\t28.24 %\n",
      "for simple_lowrank(3)\n",
      "Epoch 1 of 250 took 2.176s\n",
      "  training loss (in-iteration):\t\t2.296789\n",
      "  train accuracy:\t\t9.72 %\n",
      "  validation accuracy:\t\t12.89 %\n",
      "for rieman_lowrank(3)\n",
      "Epoch 1 of 250 took 2.998s\n",
      "  training loss (in-iteration):\t\t2.294856\n",
      "  train accuracy:\t\t12.94 %\n",
      "  validation accuracy:\t\t21.44 %\n",
      "for simple_lowrank(2)\n",
      "Epoch 1 of 250 took 2.203s\n",
      "  training loss (in-iteration):\t\t2.308591\n",
      "  train accuracy:\t\t9.79 %\n",
      "  validation accuracy:\t\t13.20 %\n",
      "for dense\n",
      "Epoch 1 of 250 took 3.786s\n",
      "  training loss (in-iteration):\t\t2.234499\n",
      "  train accuracy:\t\t20.47 %\n",
      "  validation accuracy:\t\t31.89 %\n",
      "for rieman_lowrank(2)\n",
      "Epoch 1 of 250 took 3.160s\n",
      "  training loss (in-iteration):\t\t2.251867\n",
      "  train accuracy:\t\t22.78 %\n",
      "  validation accuracy:\t\t28.55 %\n",
      "for rieman_lowrank(1)\n",
      "Epoch 1 of 250 took 3.076s\n",
      "  training loss (in-iteration):\t\t2.254571\n",
      "  train accuracy:\t\t26.93 %\n",
      "  validation accuracy:\t\t31.14 %\n",
      "for simple_lowrank(0)\n",
      "Epoch 1 of 250 took 2.270s\n",
      "  training loss (in-iteration):\t\t2.311101\n",
      "  train accuracy:\t\t7.85 %\n",
      "  validation accuracy:\t\t11.44 %\n",
      "for simple_lowrank(1)\n",
      "Epoch 1 of 250 took 2.603s\n",
      "  training loss (in-iteration):\t\t2.287926\n",
      "  train accuracy:\t\t14.29 %\n",
      "  validation accuracy:\t\t18.16 %\n",
      "for simple_lowrank(4)\n",
      "Epoch 1 of 250 took 2.159s\n",
      "  training loss (in-iteration):\t\t2.309457\n",
      "  train accuracy:\t\t7.45 %\n",
      "  validation accuracy:\t\t8.98 %\n",
      "for rieman_lowrank(4)\n",
      "Epoch 1 of 250 took 3.087s\n",
      "  training loss (in-iteration):\t\t2.276932\n",
      "  train accuracy:\t\t15.86 %\n",
      "  validation accuracy:\t\t24.56 %\n",
      "for rieman_lowrank(0)\n",
      "Epoch 2 of 250 took 3.119s\n",
      "  training loss (in-iteration):\t\t2.131938\n",
      "  train accuracy:\t\t33.78 %\n",
      "  validation accuracy:\t\t38.66 %\n",
      "for simple_lowrank(3)\n",
      "Epoch 2 of 250 took 2.270s\n",
      "  training loss (in-iteration):\t\t2.273292\n",
      "  train accuracy:\t\t16.04 %\n",
      "  validation accuracy:\t\t20.07 %\n",
      "for rieman_lowrank(3)\n",
      "Epoch 2 of 250 took 3.430s\n",
      "  training loss (in-iteration):\t\t2.260351\n",
      "  train accuracy:\t\t31.72 %\n",
      "  validation accuracy:\t\t44.80 %\n",
      "for simple_lowrank(2)\n",
      "Epoch 2 of 250 took 2.289s\n",
      "  training loss (in-iteration):\t\t2.286719\n",
      "  train accuracy:\t\t15.03 %\n",
      "  validation accuracy:\t\t19.32 %\n",
      "for dense\n",
      "Epoch 2 of 250 took 4.499s\n",
      "  training loss (in-iteration):\t\t2.009509\n",
      "  train accuracy:\t\t38.84 %\n",
      "  validation accuracy:\t\t48.17 %\n",
      "for rieman_lowrank(2)\n",
      "Epoch 2 of 250 took 3.195s\n",
      "  training loss (in-iteration):\t\t2.120723\n",
      "  train accuracy:\t\t32.68 %\n",
      "  validation accuracy:\t\t38.73 %\n",
      "for rieman_lowrank(1)\n",
      "Epoch 2 of 250 took 3.062s\n",
      "  training loss (in-iteration):\t\t2.132365\n",
      "  train accuracy:\t\t35.00 %\n",
      "  validation accuracy:\t\t39.55 %\n",
      "for simple_lowrank(0)\n",
      "Epoch 2 of 250 took 2.252s\n",
      "  training loss (in-iteration):\t\t2.291296\n",
      "  train accuracy:\t\t14.35 %\n",
      "  validation accuracy:\t\t18.35 %\n",
      "for simple_lowrank(1)\n",
      "Epoch 2 of 250 took 2.226s\n",
      "  training loss (in-iteration):\t\t2.265429\n",
      "  train accuracy:\t\t20.99 %\n",
      "  validation accuracy:\t\t25.46 %\n",
      "for simple_lowrank(4)\n",
      "Epoch 2 of 250 took 2.316s\n",
      "  training loss (in-iteration):\t\t2.289623\n",
      "  train accuracy:\t\t12.48 %\n",
      "  validation accuracy:\t\t15.85 %\n",
      "for rieman_lowrank(4)\n",
      "Epoch 2 of 250 took 3.104s\n",
      "  training loss (in-iteration):\t\t2.153881\n",
      "  train accuracy:\t\t31.48 %\n",
      "  validation accuracy:\t\t39.51 %\n",
      "for rieman_lowrank(0)\n",
      "Epoch 3 of 250 took 3.109s\n",
      "  training loss (in-iteration):\t\t1.998624\n",
      "  train accuracy:\t\t43.41 %\n",
      "  validation accuracy:\t\t47.84 %\n",
      "for simple_lowrank(3)\n",
      "Epoch 3 of 250 took 2.264s\n",
      "  training loss (in-iteration):\t\t2.247329\n",
      "  train accuracy:\t\t23.01 %\n",
      "  validation accuracy:\t\t27.01 %\n",
      "for rieman_lowrank(3)\n",
      "Epoch 3 of 250 took 3.092s\n",
      "  training loss (in-iteration):\t\t2.171783\n",
      "  train accuracy:\t\t44.79 %\n",
      "  validation accuracy:\t\t47.39 %\n",
      "for simple_lowrank(2)\n",
      "Epoch 3 of 250 took 2.219s\n",
      "  training loss (in-iteration):\t\t2.262683\n",
      "  train accuracy:\t\t21.36 %\n",
      "  validation accuracy:\t\t25.41 %\n",
      "for dense\n",
      "Epoch 3 of 250 took 3.508s\n",
      "  training loss (in-iteration):\t\t1.833223\n",
      "  train accuracy:\t\t51.57 %\n",
      "  validation accuracy:\t\t58.85 %\n",
      "for rieman_lowrank(2)\n",
      "Epoch 3 of 250 took 3.058s\n",
      "  training loss (in-iteration):\t\t1.952627\n",
      "  train accuracy:\t\t44.62 %\n",
      "  validation accuracy:\t\t50.29 %\n",
      "for rieman_lowrank(1)\n",
      "Epoch 3 of 250 took 3.044s\n",
      "  training loss (in-iteration):\t\t1.989471\n",
      "  train accuracy:\t\t43.49 %\n",
      "  validation accuracy:\t\t47.40 %\n",
      "for simple_lowrank(0)\n",
      "Epoch 3 of 250 took 2.237s\n",
      "  training loss (in-iteration):\t\t2.271455\n",
      "  train accuracy:\t\t20.82 %\n",
      "  validation accuracy:\t\t24.28 %\n",
      "for simple_lowrank(1)\n",
      "Epoch 3 of 250 took 2.209s\n",
      "  training loss (in-iteration):\t\t2.240146\n",
      "  train accuracy:\t\t28.10 %\n",
      "  validation accuracy:\t\t33.44 %\n",
      "for simple_lowrank(4)\n",
      "Epoch 3 of 250 took 2.204s\n",
      "  training loss (in-iteration):\t\t2.268751\n",
      "  train accuracy:\t\t18.82 %\n",
      "  validation accuracy:\t\t22.18 %\n",
      "for rieman_lowrank(4)\n",
      "Epoch 3 of 250 took 3.040s\n",
      "  training loss (in-iteration):\t\t1.980028\n",
      "  train accuracy:\t\t44.87 %\n",
      "  validation accuracy:\t\t51.46 %\n",
      "for rieman_lowrank(0)\n",
      "Epoch 4 of 250 took 3.061s\n",
      "  training loss (in-iteration):\t\t1.835872\n",
      "  train accuracy:\t\t50.34 %\n",
      "  validation accuracy:\t\t54.82 %\n",
      "for simple_lowrank(3)\n",
      "Epoch 4 of 250 took 2.200s\n",
      "  training loss (in-iteration):\t\t2.215890\n",
      "  train accuracy:\t\t29.26 %\n",
      "  validation accuracy:\t\t32.91 %\n",
      "for rieman_lowrank(3)\n",
      "Epoch 4 of 250 took 3.073s\n",
      "  training loss (in-iteration):\t\t2.019169\n",
      "  train accuracy:\t\t46.84 %\n",
      "  validation accuracy:\t\t50.23 %\n",
      "for simple_lowrank(2)\n",
      "Epoch 4 of 250 took 2.211s\n",
      "  training loss (in-iteration):\t\t2.234221\n",
      "  train accuracy:\t\t26.94 %\n",
      "  validation accuracy:\t\t31.02 %\n",
      "for dense\n",
      "Epoch 4 of 250 took 3.496s\n",
      "  training loss (in-iteration):\t\t1.676785\n",
      "  train accuracy:\t\t60.01 %\n",
      "  validation accuracy:\t\t64.88 %\n",
      "for rieman_lowrank(2)\n",
      "Epoch 4 of 250 took 3.102s\n",
      "  training loss (in-iteration):\t\t1.786550\n",
      "  train accuracy:\t\t53.01 %\n",
      "  validation accuracy:\t\t56.15 %\n",
      "for rieman_lowrank(1)\n",
      "Epoch 4 of 250 took 3.062s\n",
      "  training loss (in-iteration):\t\t1.830235\n",
      "  train accuracy:\t\t50.35 %\n",
      "  validation accuracy:\t\t53.61 %\n",
      "for simple_lowrank(0)\n",
      "Epoch 4 of 250 took 2.257s\n",
      "  training loss (in-iteration):\t\t2.248777\n",
      "  train accuracy:\t\t26.03 %\n",
      "  validation accuracy:\t\t29.33 %\n",
      "for simple_lowrank(1)\n",
      "Epoch 4 of 250 took 2.247s\n",
      "  training loss (in-iteration):\t\t2.210177\n",
      "  train accuracy:\t\t34.97 %\n",
      "  validation accuracy:\t\t38.92 %\n",
      "for simple_lowrank(4)\n",
      "Epoch 4 of 250 took 2.225s\n",
      "  training loss (in-iteration):\t\t2.243852\n",
      "  train accuracy:\t\t24.78 %\n",
      "  validation accuracy:\t\t28.34 %\n",
      "for rieman_lowrank(4)\n",
      "Epoch 4 of 250 took 3.122s\n",
      "  training loss (in-iteration):\t\t1.789458\n",
      "  train accuracy:\t\t54.21 %\n",
      "  validation accuracy:\t\t58.31 %\n",
      "for rieman_lowrank(0)\n",
      "Epoch 5 of 250 took 3.099s\n",
      "  training loss (in-iteration):\t\t1.668904\n",
      "  train accuracy:\t\t56.54 %\n",
      "  validation accuracy:\t\t60.73 %\n",
      "for simple_lowrank(3)\n",
      "Epoch 5 of 250 took 2.200s\n",
      "  training loss (in-iteration):\t\t2.175348\n",
      "  train accuracy:\t\t33.76 %\n",
      "  validation accuracy:\t\t37.60 %\n",
      "for rieman_lowrank(3)\n",
      "Epoch 5 of 250 took 3.066s\n",
      "  training loss (in-iteration):\t\t1.845022\n",
      "  train accuracy:\t\t53.95 %\n",
      "  validation accuracy:\t\t60.34 %\n",
      "for simple_lowrank(2)\n",
      "Epoch 5 of 250 took 2.216s\n",
      "  training loss (in-iteration):\t\t2.196460\n",
      "  train accuracy:\t\t31.70 %\n",
      "  validation accuracy:\t\t34.07 %\n",
      "for dense\n",
      "Epoch 5 of 250 took 3.523s\n",
      "  training loss (in-iteration):\t\t1.535027\n",
      "  train accuracy:\t\t65.16 %\n",
      "  validation accuracy:\t\t69.72 %\n",
      "for rieman_lowrank(2)\n",
      "Epoch 5 of 250 took 3.073s\n",
      "  training loss (in-iteration):\t\t1.645097\n",
      "  train accuracy:\t\t56.92 %\n",
      "  validation accuracy:\t\t60.29 %\n",
      "for rieman_lowrank(1)\n",
      "Epoch 5 of 250 took 3.062s\n",
      "  training loss (in-iteration):\t\t1.674300\n",
      "  train accuracy:\t\t55.51 %\n",
      "  validation accuracy:\t\t57.99 %\n",
      "for simple_lowrank(0)\n",
      "Epoch 5 of 250 took 2.224s\n",
      "  training loss (in-iteration):\t\t2.220933\n",
      "  train accuracy:\t\t30.22 %\n",
      "  validation accuracy:\t\t32.40 %\n",
      "for simple_lowrank(1)\n",
      "Epoch 5 of 250 took 2.218s\n",
      "  training loss (in-iteration):\t\t2.172163\n",
      "  train accuracy:\t\t40.26 %\n",
      "  validation accuracy:\t\t43.03 %\n",
      "for simple_lowrank(4)\n",
      "Epoch 5 of 250 took 2.225s\n",
      "  training loss (in-iteration):\t\t2.212801\n",
      "  train accuracy:\t\t30.05 %\n",
      "  validation accuracy:\t\t32.31 %\n",
      "for rieman_lowrank(4)\n",
      "Epoch 5 of 250 took 3.058s\n",
      "  training loss (in-iteration):\t\t1.624603\n",
      "  train accuracy:\t\t58.89 %\n",
      "  validation accuracy:\t\t62.19 %\n",
      "for rieman_lowrank(0)\n",
      "Epoch 6 of 250 took 3.080s\n",
      "  training loss (in-iteration):\t\t1.517646\n",
      "  train accuracy:\t\t61.80 %\n",
      "  validation accuracy:\t\t65.52 %\n",
      "for simple_lowrank(3)\n",
      "Epoch 6 of 250 took 2.229s\n",
      "  training loss (in-iteration):\t\t2.122760\n",
      "  train accuracy:\t\t38.05 %\n",
      "  validation accuracy:\t\t41.80 %\n",
      "for rieman_lowrank(3)\n",
      "Epoch 6 of 250 took 3.067s\n",
      "  training loss (in-iteration):\t\t1.679642\n",
      "  train accuracy:\t\t62.07 %\n",
      "  validation accuracy:\t\t65.54 %\n",
      "for simple_lowrank(2)\n",
      "Epoch 6 of 250 took 2.330s\n",
      "  training loss (in-iteration):\t\t2.147576\n",
      "  train accuracy:\t\t34.61 %\n",
      "  validation accuracy:\t\t35.98 %\n",
      "for dense\n",
      "Epoch 6 of 250 took 3.528s\n",
      "  training loss (in-iteration):\t\t1.408051\n",
      "  train accuracy:\t\t68.87 %\n",
      "  validation accuracy:\t\t72.69 %\n",
      "for rieman_lowrank(2)\n",
      "Epoch 6 of 250 took 3.093s\n",
      "  training loss (in-iteration):\t\t1.526264\n",
      "  train accuracy:\t\t60.52 %\n",
      "  validation accuracy:\t\t63.88 %\n",
      "for rieman_lowrank(1)\n",
      "Epoch 6 of 250 took 3.215s\n",
      "  training loss (in-iteration):\t\t1.536772\n",
      "  train accuracy:\t\t58.87 %\n",
      "  validation accuracy:\t\t61.14 %\n",
      "for simple_lowrank(0)\n",
      "Epoch 6 of 250 took 2.276s\n",
      "  training loss (in-iteration):\t\t2.186263\n",
      "  train accuracy:\t\t32.79 %\n",
      "  validation accuracy:\t\t35.25 %\n",
      "for simple_lowrank(1)\n",
      "Epoch 6 of 250 took 2.242s\n",
      "  training loss (in-iteration):\t\t2.123061\n",
      "  train accuracy:\t\t43.91 %\n",
      "  validation accuracy:\t\t46.78 %\n",
      "for simple_lowrank(4)\n",
      "Epoch 6 of 250 took 2.220s\n",
      "  training loss (in-iteration):\t\t2.173345\n",
      "  train accuracy:\t\t34.31 %\n",
      "  validation accuracy:\t\t36.27 %\n",
      "for rieman_lowrank(4)\n",
      "Epoch 6 of 250 took 3.053s\n",
      "  training loss (in-iteration):\t\t1.492212\n",
      "  train accuracy:\t\t62.04 %\n",
      "  validation accuracy:\t\t65.23 %\n",
      "for rieman_lowrank(0)\n",
      "Epoch 7 of 250 took 3.062s\n",
      "  training loss (in-iteration):\t\t1.383690\n",
      "  train accuracy:\t\t65.68 %\n",
      "  validation accuracy:\t\t68.77 %\n",
      "for simple_lowrank(3)\n",
      "Epoch 7 of 250 took 2.224s\n",
      "  training loss (in-iteration):\t\t2.057655\n",
      "  train accuracy:\t\t41.95 %\n",
      "  validation accuracy:\t\t45.56 %\n",
      "for rieman_lowrank(3)\n",
      "Epoch 7 of 250 took 3.096s\n",
      "  training loss (in-iteration):\t\t1.531283\n",
      "  train accuracy:\t\t65.58 %\n",
      "  validation accuracy:\t\t68.00 %\n",
      "for simple_lowrank(2)\n",
      "Epoch 7 of 250 took 2.228s\n",
      "  training loss (in-iteration):\t\t2.086384\n",
      "  train accuracy:\t\t35.94 %\n",
      "  validation accuracy:\t\t36.57 %\n",
      "for dense\n",
      "Epoch 7 of 250 took 3.516s\n",
      "  training loss (in-iteration):\t\t1.299437\n",
      "  train accuracy:\t\t71.31 %\n",
      "  validation accuracy:\t\t75.07 %\n",
      "for rieman_lowrank(2)\n",
      "Epoch 7 of 250 took 3.064s\n",
      "  training loss (in-iteration):\t\t1.421576\n",
      "  train accuracy:\t\t64.15 %\n",
      "  validation accuracy:\t\t67.70 %\n",
      "for rieman_lowrank(1)\n",
      "Epoch 7 of 250 took 3.062s\n",
      "  training loss (in-iteration):\t\t1.417699\n",
      "  train accuracy:\t\t62.32 %\n",
      "  validation accuracy:\t\t65.18 %\n",
      "for simple_lowrank(0)\n",
      "Epoch 7 of 250 took 2.288s\n",
      "  training loss (in-iteration):\t\t2.143255\n",
      "  train accuracy:\t\t35.47 %\n",
      "  validation accuracy:\t\t37.72 %\n",
      "for simple_lowrank(1)\n",
      "Epoch 7 of 250 took 2.264s\n",
      "  training loss (in-iteration):\t\t2.060976\n",
      "  train accuracy:\t\t46.81 %\n",
      "  validation accuracy:\t\t49.50 %\n",
      "for simple_lowrank(4)\n",
      "Epoch 7 of 250 took 2.227s\n",
      "  training loss (in-iteration):\t\t2.122411\n",
      "  train accuracy:\t\t38.09 %\n",
      "  validation accuracy:\t\t39.66 %\n",
      "for rieman_lowrank(4)\n",
      "Epoch 7 of 250 took 3.067s\n",
      "  training loss (in-iteration):\t\t1.382287\n",
      "  train accuracy:\t\t64.88 %\n",
      "  validation accuracy:\t\t68.77 %\n",
      "for rieman_lowrank(0)\n",
      "Epoch 8 of 250 took 3.065s\n",
      "  training loss (in-iteration):\t\t1.269829\n",
      "  train accuracy:\t\t69.01 %\n",
      "  validation accuracy:\t\t72.72 %\n",
      "for simple_lowrank(3)\n",
      "Epoch 8 of 250 took 2.218s\n",
      "  training loss (in-iteration):\t\t1.979600\n",
      "  train accuracy:\t\t45.77 %\n",
      "  validation accuracy:\t\t49.53 %\n",
      "for rieman_lowrank(3)\n",
      "Epoch 8 of 250 took 3.098s\n",
      "  training loss (in-iteration):\t\t1.406126\n",
      "  train accuracy:\t\t67.21 %\n",
      "  validation accuracy:\t\t69.67 %\n",
      "for simple_lowrank(2)\n",
      "Epoch 8 of 250 took 2.221s\n",
      "  training loss (in-iteration):\t\t2.013249\n",
      "  train accuracy:\t\t36.72 %\n",
      "  validation accuracy:\t\t37.22 %\n",
      "for dense\n",
      "Epoch 8 of 250 took 3.490s\n",
      "  training loss (in-iteration):\t\t1.205949\n",
      "  train accuracy:\t\t73.24 %\n",
      "  validation accuracy:\t\t77.01 %\n",
      "for rieman_lowrank(2)\n",
      "Epoch 8 of 250 took 3.085s\n",
      "  training loss (in-iteration):\t\t1.328471\n",
      "  train accuracy:\t\t67.61 %\n",
      "  validation accuracy:\t\t71.07 %\n",
      "for rieman_lowrank(1)\n",
      "Epoch 8 of 250 took 3.061s\n",
      "  training loss (in-iteration):\t\t1.314702\n",
      "  train accuracy:\t\t65.54 %\n",
      "  validation accuracy:\t\t68.92 %\n",
      "for simple_lowrank(0)\n",
      "Epoch 8 of 250 took 2.222s\n",
      "  training loss (in-iteration):\t\t2.090136\n",
      "  train accuracy:\t\t37.92 %\n",
      "  validation accuracy:\t\t40.11 %\n",
      "for simple_lowrank(1)\n",
      "Epoch 8 of 250 took 2.205s\n",
      "  training loss (in-iteration):\t\t1.984606\n",
      "  train accuracy:\t\t49.27 %\n",
      "  validation accuracy:\t\t51.39 %\n",
      "for simple_lowrank(4)"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    from mnist import load_dataset\n",
    "    X_train,y_train,X_val,y_val,X_test,y_test = load_dataset()\n",
    "    print(X_train.shape,y_train.shape)\n",
    "    \n",
    "    ranks = [8, 16, 32, 64, 128]\n",
    "    for rk in ranks:\n",
    "        comparison(X_train,y_train,X_val,y_val,X_test,y_test, rank=rk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
